{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import argparse\n",
    "from datetime import datetime \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    # Show debugging output\n",
    "    tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "    argContainer = get_commandline_args()\n",
    "    dataList = generate_data(argContainer)\n",
    "    create_estimator(dataList,argContainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(argContainer):\n",
    "    dataList = [] \n",
    "    flags, detail = argContainer.parse_known_args()\n",
    "    num_samples = flags.num_samples\n",
    "    x_train = np.random.rand(num_samples).astype(np.float32)\n",
    "    dataList.append(x_train)\n",
    "    noise = np.random.normal(scale=0.01, size=len(x_train)) \n",
    "    y_train = (0.1 * x_train) + 0.3 + noise\n",
    "    dataList.append(y_train)\n",
    "    x_test = np.random.rand(len(x_train)).astype(np.float32)\n",
    "    dataList.append(x_test)\n",
    "    y_test = (0.1 * x_test) + 0.3 + noise\n",
    "    dataList.append(y_test)\n",
    "    return dataList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_commandline_args():\n",
    "   parser = argparse.ArgumentParser()\n",
    "   parser.add_argument('--learning_rate', type=float, help='Learning Rate', default=0.025)  \n",
    "   parser.add_argument('--num_samples', type=int, help='Num Samples', default=100000)  \n",
    "   #print (parser.num_samples)\n",
    "   version = int(datetime.now().strftime(\"%s\"))\n",
    "   parser.add_argument('--rundir', type=str, help='Run Directory', default='runs/%s' %version)  \n",
    "   return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input_func(dataList):\n",
    "    x_train = dataList[0]\n",
    "    y_train = dataList[1]\n",
    "    return tf.estimator.inputs.numpy_input_fn({'x' : x_train}, y_train, batch_size=4, num_epochs=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_input_func(dataList):\n",
    "    x_train = dataList[2]\n",
    "    y_train = dataList[3]\n",
    "    return tf.estimator.inputs.numpy_input_fn({'x' : x_train}, y_train, batch_size=4, num_epochs=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn_predict(estimator):\n",
    "    return tf.estimator.inputs.numpy_input_fn({'x' :np.random.rand(10).astype(np.float32)}, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_estimator(dataList,argContainer):\n",
    "\n",
    "    flags,details = argContainer.parse_known_args()\n",
    "\n",
    "    feat_cols = [tf.feature_column.numeric_column('x', shape=[1])]\n",
    "\n",
    "    estimator = tf.estimator.LinearRegressor(feature_columns=feat_cols, model_dir='./' + flags.rundir)\n",
    "\n",
    "    estimator.train(input_fn=train_input_func(dataList), steps=1000)\n",
    "\n",
    "    train_metrics = estimator.evaluate(input_fn=train_input_func(dataList), steps=1000)\n",
    "\n",
    "    eval_metrics = estimator.evaluate(input_fn=eval_input_func(dataList), steps=1000)\n",
    "\n",
    "    print(\"train metrics: {}\".format(train_metrics))\n",
    "\n",
    "    print(\"eval metrics: {}\".format(eval_metrics))\n",
    "\n",
    "    list(estimator.predict(input_fn=input_fn_predict(estimator)))\n",
    "\n",
    "    predictions = []\n",
    "    for x in estimator.predict(input_fn=input_fn_predict(estimator)):\n",
    "        predictions.append(x['predictions'])\n",
    "    print (predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train metrics: {'global_step': 1000, 'average_loss': 0.0001200811, 'loss': 0.00048032441}\n",
      "eval metrics: {'global_step': 1000, 'average_loss': 0.00011962984, 'loss': 0.00047851936}\n",
      "[array([ 0.39025635], dtype=float32), array([ 0.33101499], dtype=float32), array([ 0.3505643], dtype=float32), array([ 0.33085006], dtype=float32), array([ 0.2987951], dtype=float32), array([ 0.30312449], dtype=float32), array([ 0.3727245], dtype=float32), array([ 0.36118421], dtype=float32), array([ 0.32459033], dtype=float32), array([ 0.33372137], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
