![PipelineAI Logo](https://pipeline.ai/assets/img/logo/pipelineai-logo.png)

# PipelineAI Quick Start (CPU + GPU)
Train and Deploy your ML and AI Models in the Following Environments:
* [Community Edition](/docs/quickstart/community)
* [Docker](/docs/quickstart/docker)
* [Kubernetes](/docs/quickstart/kubernetes)
* [AWS SageMaker](/docs/quickstart/sagemaker)

# Having Issues?  Contact Us Anytime... We're Always Awake.
* Slack:  http://joinslack.pipeline.ai
* Email:  [help@pipeline.ai](mailto:help@pipeline.ai)
* Web:  https://support.pipeline.ai
* YouTube:  http://youtube.pipeline.ai
* Slideshare:  http://slideshare.pipeline.ai
* [Troubleshooting Guide](/docs/troubleshooting)

# PipelineAI Community Events
* [PipelineAI Deep Learning Workshops (TensorFlow + Spark + GPUs)](https://www.eventbrite.com/d/worldwide/pipelineai/?mode=search)
* [Advanced Spark and TensorFlow Meetup (Global)](https://www.meetup.com/Advanced-Spark-and-TensorFlow-Meetup/)

# PipelineAI [Home](http://pipeline.ai)
[![PipelineAI Home](http://pipeline.ai/assets/img/pipelineai-home.png)](http://pipeline.ai)
[![PipelineAI Home 1](http://pipeline.ai/assets/img/pipelineai-home-1.png)](http://pipeline.ai)
[![PipelineAI Home 2](http://pipeline.ai/assets/img/pipelineai-home-2.png)](http://pipeline.ai)

# PipelineAI [Features](http://pipeline.ai/features)

## Consistent, Immutable, Reproducible Model Runtimes
![Consistent Model Environments](http://pipeline.ai/assets/img/docker-gobbles-ml.png)

Each model is built into a separate Docker image with the appropriate Python, C++, and Java/Scala Runtime Libraries for training or prediction.

Use the same Docker Image from Local Laptop to Production to avoid dependency surprises.

## Sample Machine Learning and AI Models
Click [**HERE**](https://github.com/PipelineAI/models/tree/master) to view model samples for the following:
* Scikit-Learn
* TensorFlow
* Keras
* Spark ML (formerly called Spark MLlib)
* XGBoost
* PyTorch
* Caffe/2
* Theano
* MXNet
* PMML/PFA
* Custom Java/Python/C++ Ensembles

![Nvidia GPU](http://pipeline.ai/assets/img/nvidia-cuda-338x181.png) ![TensorFlow](http://pipeline.ai/assets/img/tensorflow-logo-202x168.png) 

![Spark ML](http://pipeline.ai/assets/img/spark-logo-254x163.png) ![Scikit-Learn](http://pipeline.ai/assets/img/scikit-logo-277x150.png) 

![R](http://pipeline.ai/assets/img/r-logo-280x212.png) ![PMML](http://pipeline.ai/img/pmml-logo-210x96.png)

![Xgboost](http://pipeline.ai/assets/img/xgboost-logo-280x120.png) ![Model Ensembles](http://pipeline.ai/assets/img/ensemble-logo-285x125.png)

## Supported Model Runtimes (CPU and GPU)
* Python (Scikit, TensorFlow, etc)
* Java
* Scala
* Spark ML
* C++
* Caffe2
* Theano
* TensorFlow Serving
* Nvidia TensorRT (TensorFlow, Caffe2)
* MXNet
* CNTK
* ONNX

## Supported Streaming Engines
* Kafka
* Kinesis
* Flink
* Spark Streaming
* Heron
* Storm

# Advanced PipelineAI Product Features
* Click [HERE](http://pipeline.ai/products) to compare PipelineAI Products.

## Drag N' Drop Model Deploy
![PipelineAI Drag n' Drop Model Deploy UI](http://pipeline.ai/assets/img/drag-n-drop-tri-color.png)

## Generate Optimize Model Versions Upon Upload
![Automatic Model Optimization and Native Code Generation](http://pipeline.ai/assets/img/automatic-model-optimization-native-code-generation.png)

## Distributed Model Training and Hyper-Parameter Tuning
![PipelineAI Advanced Model Training UI](http://pipeline.ai/assets/img/pipelineai-train-compare-ui.png)

![PipelineAI Advanced Model Training UI 2](http://pipeline.ai/assets/img/pipelineai-train-compare-ui-2.png)

## Continuously Deploy Models to Clusters of PipelineAI Servers
![PipelineAI Weavescope Kubernetes Cluster](http://pipeline.ai/assets/img/weavescope-with-header.png)

## View Real-Time Prediction Stream
![Live Stream Predictions](http://pipeline.ai/assets/img/live-stream-predictions.png)

## Compare Both Offline (Batch) and Real-Time Model Performance
![PipelineAI Model Comparison](http://pipeline.ai/assets/img/dashboard-batch-and-realtime.png)

## Compare Response Time, Throughput, and Cost-Per-Prediction
![PipelineAI Compare Performance and Cost Per Prediction](http://pipeline.ai/assets/img/compare-cost-per-prediction.png)

## Shift Live Traffic to Maximize Revenue and Minimize Cost
![PipelineAI Traffic Shift Multi-armed Bandit Maxmimize Revenue Minimize Cost](http://pipeline.ai/assets/img/maximize-revenue-minimize-costs.png)

## Continuously Fix Borderline Predictions through Crowd Sourcing 
![Borderline Prediction Fixing and Crowd Sourcing](http://pipeline.ai/assets/img/fix-slack.png)

