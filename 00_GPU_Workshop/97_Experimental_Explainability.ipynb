{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 41, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"/opt/conda/lib/python3.6/imp.py\", line 243, in load_module\n    return load_dynamic(name, filename, file)\n  File \"/opt/conda/lib/python3.6/imp.py\", line 343, in load_dynamic\n    return _load(spec)\nImportError: libcusolver.so.8.0: cannot open shared object file: No such file or directory\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdlopenflags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_default_dlopen_flags\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRTLD_GLOBAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_mod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0m_pywrap_tensorflow_internal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mswig_import_helper\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0m_mod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_pywrap_tensorflow_internal'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/imp.py\u001b[0m in \u001b[0;36mload_module\u001b[0;34m(name, file, filename, details)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mload_dynamic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mtype_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPKG_DIRECTORY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/imp.py\u001b[0m in \u001b[0;36mload_dynamic\u001b[0;34m(name, path, file)\u001b[0m\n\u001b[1;32m    342\u001b[0m             name=name, loader=loader, origin=path)\n\u001b[0;32m--> 343\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: libcusolver.so.8.0: cannot open shared object file: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a7aabf288f44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtutorials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmnist\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# pylint: disable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# Protocol buffers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msome\u001b[0m \u001b[0mcommon\u001b[0m \u001b[0mreasons\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msolutions\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mInclude\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mentire\u001b[0m \u001b[0mstack\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m above this error message when asking for help.\"\"\" % traceback.format_exc()\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 41, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"/opt/conda/lib/python3.6/imp.py\", line 243, in load_module\n    return load_dynamic(name, filename, file)\n  File \"/opt/conda/lib/python3.6/imp.py\", line 343, in load_dynamic\n    return _load(spec)\nImportError: libcusolver.so.8.0: cannot open shared object file: No such file or directory\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help."
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skater'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c04560cd2699>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# import \"Skater\" related functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mskater\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_noise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflip_pixels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_transformation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskater\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0min_between\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgreater_than\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgreater_than_or_equal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mequal_to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskater\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_interpretation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnni\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeep_interpreter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDeepInterpreter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'skater'"
     ]
    }
   ],
   "source": [
    "# import \"Skater\" related functions\n",
    "%matplotlib inline\n",
    "from skater.util.image_ops import load_image, show_image, normalize, add_noise, flip_pixels, image_transformation\n",
    "from skater.util.image_ops import in_between, greater_than, greater_than_or_equal, equal_to\n",
    "from skater.core.local_interpretation.dnni.deep_interpreter import DeepInterpreter\n",
    "from skater.core.visualizer.image_relevance_visualizer import visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "current_level = tf.logging.get_verbosity()\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "mnist = input_data.read_data_sets(\"/tmp/\", one_hot=True)\n",
    "tf.logging.set_verbosity(current_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.005\n",
    "num_steps = 2000\n",
    "batch_size = 128\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer number of neurons\n",
    "n_hidden_2 = 256 # 2nd layer number of neurons\n",
    "num_input = 784 # MNIST data input (img shape: 28*28)\n",
    "num_classes = 10 # MNIST total classes (0-9 digits)\n",
    "\n",
    "# tf Graph input as tensors\n",
    "X = tf.placeholder(\"float\", [None, num_input] , name=\"input\")\n",
    "Y = tf.placeholder(\"float\", [None, num_classes], name=\"output\")\n",
    "\n",
    "# weights and biases for each Layer\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([num_input, n_hidden_1], mean=0.0, stddev=0.05)),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2], mean=0.0, stddev=0.05)),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, num_classes], mean=0.0, stddev=0.05))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.zeros([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.zeros([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.zeros([num_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x, act=tf.nn.relu): \n",
    "    layer_1 = act(tf.add(tf.matmul(x, weights['h1']), biases['b1']))\n",
    "    layer_2 = act(tf.add(tf.matmul(layer_1, weights['h2']), biases['b2']))\n",
    "    out_layer = tf.add(tf.matmul(layer_2, weights['out']), biases['out'], name=\"absolute_output\")\n",
    "    return out_layer\n",
    "\n",
    "# Construct model\n",
    "logits = model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 Minibatch Loss= 1.9131 Training Accuracy= 0.516\n",
      "Step 100 Minibatch Loss= 0.1012 Training Accuracy= 0.969\n",
      "Step 200 Minibatch Loss= 0.1296 Training Accuracy= 0.953\n",
      "Step 300 Minibatch Loss= 0.1440 Training Accuracy= 0.953\n",
      "Step 400 Minibatch Loss= 0.1537 Training Accuracy= 0.953\n",
      "Step 500 Minibatch Loss= 0.0329 Training Accuracy= 1.000\n",
      "Step 600 Minibatch Loss= 0.1275 Training Accuracy= 0.945\n",
      "Step 700 Minibatch Loss= 0.0477 Training Accuracy= 0.977\n",
      "Step 800 Minibatch Loss= 0.0629 Training Accuracy= 0.969\n",
      "Step 900 Minibatch Loss= 0.0102 Training Accuracy= 1.000\n",
      "Step 1000 Minibatch Loss= 0.0546 Training Accuracy= 0.977\n",
      "Step 1100 Minibatch Loss= 0.0540 Training Accuracy= 0.984\n",
      "Step 1200 Minibatch Loss= 0.0514 Training Accuracy= 0.992\n",
      "Step 1300 Minibatch Loss= 0.0152 Training Accuracy= 0.992\n",
      "Step 1400 Minibatch Loss= 0.0226 Training Accuracy= 0.992\n",
      "Step 1500 Minibatch Loss= 0.0262 Training Accuracy= 0.992\n",
      "Step 1600 Minibatch Loss= 0.0318 Training Accuracy= 0.992\n",
      "Step 1700 Minibatch Loss= 0.0129 Training Accuracy= 1.000\n",
      "Step 1800 Minibatch Loss= 0.0174 Training Accuracy= 0.992\n",
      "Step 1900 Minibatch Loss= 0.0190 Training Accuracy= 0.992\n",
      "Step 2000 Minibatch Loss= 0.0540 Training Accuracy= 0.977\n",
      "success\n"
     ]
    }
   ],
   "source": [
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "for step in range(1, num_steps+1):\n",
    "    batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "    # Run optimization op (backprop)\n",
    "    sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
    "    if step % 100 == 0 or step == 1:\n",
    "        # Calculate batch loss and accuracy\n",
    "        loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x, Y: batch_y})\n",
    "        print(\"Step {} Minibatch Loss= {:.4f} Training Accuracy= {:.3f}\".format(step, loss, acc))\n",
    "\n",
    "print(\"success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9748\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy for MNIST test images\n",
    "test_x = mnist.test.images\n",
    "test_y = mnist.test.labels\n",
    "\n",
    "print(\"Test accuracy:\", sess.run(accuracy, feed_dict={X: test_x, Y: test_y}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./explanations/models/simple_mnist-model-2000'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(sess, './explanations/models/simple_mnist-model', global_step=num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-17 02:21:57,127 - LRP - INFO - Epsilon value: 0.0001\n",
      "2018-07-17 02:21:57,129 - BaseGradient - INFO - Executing operations ...\n",
      "2018-07-17 02:21:57,234 - IntegratedGradients - INFO - Executing operations to compute relevance using Integrated Gradient\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1, 784)\n",
      "Y shape: (1, 10)\n",
      "Predicted Class: [1]\n"
     ]
    }
   ],
   "source": [
    "test_idx = 189\n",
    "input_x_i = test_x[[test_idx]]\n",
    "input_y_i = test_y[test_idx].reshape(1, 10)\n",
    "with DeepInterpreter(session=sess) as di:\n",
    "    # 1. Restore the persisted model\n",
    "    # 2. Retrieve the input tensor from the restored model\n",
    "    saver = tf.train.import_meta_graph('./explanations/models/simple_mnist-model-2000.meta')\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('./explanations/models/'))\n",
    "    graph = tf.get_default_graph()\n",
    "    X = graph.get_tensor_by_name(\"input:0\")\n",
    "    Y = graph.get_tensor_by_name(\"output:0\")\n",
    "    target_tensor = model(X)\n",
    "    y_class = tf.argmax(target_tensor, 1)\n",
    "\n",
    "    xs = input_x_i\n",
    "    ys = input_y_i\n",
    "    print(\"X shape: {}\".format(xs.shape))\n",
    "    print(\"Y shape: {}\".format(ys.shape))\n",
    "    \n",
    "    # Predictions\n",
    "    eval_dict = {X: xs, Y: ys}\n",
    "    predicted_class = sess.run(y_class, feed_dict=eval_dict)\n",
    "    print(\"Predicted Class: {}\".format(predicted_class))\n",
    "    #relevance_scores = di.explain('elrp', target_tensor * ys, X, xs, use_case='image')\n",
    "    relevance_scores = {\n",
    "       'elrp': di.explain('elrp', target_tensor * ys, X, xs, use_case='image'),\n",
    "        'integrated gradient': di.explain('ig', target_tensor * ys, X, xs, use_case='image'),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABBIAAAFXCAYAAAAf9W2+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJAAAAADZBAkAAABANkECAAAAkO3/A33AAhwL7aWbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1296x432 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "input_x = [input_x_i.reshape(28, 28)]\n",
    "input_y = input_y_i\n",
    "\n",
    "n_cols = int(len(relevance_scores)) + 1 # +1 to add a column for the original image\n",
    "n_rows = len(input_x) \n",
    "fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(6*n_cols, 6*n_rows))\n",
    "\n",
    "# set the properties for text\n",
    "font = {'family': 'avenir',\n",
    "        'color':  'white',\n",
    "        'weight': 'normal',\n",
    "        'size': 14,\n",
    "        }\n",
    "\n",
    "fig.patch.set_facecolor('black')\n",
    "for index, xi in enumerate(input_x):\n",
    "    ax = axes.flatten()[index*n_cols]\n",
    "    visualize(xi, cmap='gray', axis=axes[index], \n",
    "              alpha_edges=1.0, alpha_bgcolor=1).set_title('Original Image: {}'.format(input_y[index]), fontdict=font)\n",
    "    for j, r_type in enumerate(relevance_scores):\n",
    "        axj = axes.flatten()[index*n_cols+j+1]\n",
    "        # Remember to reshape the relevance_score matrix as a 2-D array\n",
    "        # Red: highlights positive relevance\n",
    "        # Blue: highlights negative relevance\n",
    "        visualize(relevance_scores[r_type][index].reshape(28, 28), original_input_img=xi, axis=axj, \n",
    "                  percentile=99,  alpha_edges=1.0, \n",
    "                  alpha_bgcolor=0.75).set_title('Relevance Type: \"{}\"'.format(r_type), fontdict=font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
